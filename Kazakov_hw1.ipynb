{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from tqdm import tqdm\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import RAKE\n",
    "from summa import keywords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = ['https://ria.ru/20211109/egipet-1758078826.html',\n",
    "            'https://ria.ru/20211031/zabroshki-1756883477.html',\n",
    "            'https://ria.ru/20211029/aviabilety-1756545652.html',\n",
    "            'https://ria.ru/20211023/venesuela-1755854229.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "all_articles = []\n",
    "for art in tqdm(articles):\n",
    "    art_dict = {}\n",
    "    req = requests.get(art, headers={'User-Agent': ua.random})\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    inf = soup.find_all('div', {'class': 'article__text'})\n",
    "    art_dict['text'] = ' '.join([i.text for i in inf])\n",
    "    keywords_inf = soup.find('meta', {'name': 'keywords'})\n",
    "    art_dict['keywords'] = keywords_inf['content'].split(', ')\n",
    "    all_articles.append(art_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ручная разметка и конкатенация двух наборов ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keywords = [['безопасность', 'египет', 'пять звезд', 'отдых', 'рейс', 'авиакомпания', \n",
    "                'коронавирусная инфекция', 'гостиница', 'аэропорт', 'отель', 'чартер'],\n",
    "               ['заброшка', 'здание', 'атмосфера', 'экскурсия', 'россия', 'покинутое здание'],\n",
    "               ['экономия', 'эффект вторника', 'билет', 'турист', 'рейс', 'стыковочный рейс', \n",
    "                'лоукостер', 'авиабилет', 'коронавирус', 'маршрут', 'хорошая цена'],\n",
    "               ['тропический остров маргарита', 'остров', 'тропический остров', 'маргарита', \n",
    "                'венесуэла', 'курорт', 'деньги', 'интернет', 'отдых', 'песчаный пляж', 'пляж', \n",
    "                'достопримечательность', 'музей', 'местная кухня', 'кухня', 'беспошлинная торговля']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_keywords(art_dict, keys):\n",
    "    print('текст:', art_dict['text'][:200] + '...')\n",
    "    print('мои ключевые слова:', keys)\n",
    "    print('ключевые слова с сайта:', art_dict['keywords'])\n",
    "    art_dict['keywords'] = list(set(art_dict['keywords'] + keys))\n",
    "    print('все ключевые слова (золотой стандарт):', art_dict['keywords'], '\\n')\n",
    "    return art_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "текст: МОСКВА, 9 ноя — РИА Новости, Светлана Баева. Сегодня, спустя шесть лет после крушения авиалайнера, следовавшего из Шарм-эш-Шейха в Санкт-Петербург, на курорты Египта из России снова начинают летать ча...\n",
      "мои ключевые слова: ['безопасность', 'египет', 'пять звезд', 'отдых', 'рейс', 'авиакомпания', 'коронавирусная инфекция', 'гостиница', 'аэропорт', 'отель', 'чартер']\n",
      "ключевые слова с сайта: ['египет', 'шарм-эш-шейх', 'хургада', 'маршруты - туризм', 'самолеты', 'авиакомпании', 'туристы', 'отели', 'туризм', 'куда поехать', 'отдых на море', 'куда можно лететь']\n",
      "все ключевые слова (золотой стандарт): ['египет', 'туризм', 'куда можно лететь', 'авиакомпания', 'туристы', 'чартер', 'авиакомпании', 'шарм-эш-шейх', 'отдых на море', 'пять звезд', 'отдых', 'безопасность', 'самолеты', 'куда поехать', 'рейс', 'маршруты - туризм', 'гостиница', 'хургада', 'коронавирусная инфекция', 'отель', 'отели', 'аэропорт'] \n",
      "\n",
      "текст: МОСКВА, 31 окт — РИА Новости, Светлана Баева. Выбитые окна зияют темными глазницами, двери заколочены, на ветхой крыше растут деревья. Одних туристов пугают покинутые здания, заводы и даже города. Дру...\n",
      "мои ключевые слова: ['заброшка', 'здание', 'атмосфера', 'экскурсия', 'россия', 'покинутое здание']\n",
      "ключевые слова с сайта: ['япония', 'воронеж', 'туту.ру', 'туризм', 'инстаграм', 'чернобыльская аэс', 'маршруты - туризм', 'патриот', 'впечатления - туризм', 'хэллоуин', 'республика крым', 'норильск', 'воркута', 'калининградская область', 'московская область (подмосковье)', 'туристы', 'куда сходить ', 'куда поехать в выходные', 'куда поехать', 'куда можно лететь']\n",
      "все ключевые слова (золотой стандарт): ['туризм', 'куда можно лететь', 'куда поехать в выходные', 'туристы', 'покинутое здание', 'патриот', 'япония', 'туту.ру', 'республика крым', 'воркута', 'куда сходить ', 'московская область (подмосковье)', 'куда поехать', 'здание', 'маршруты - туризм', 'воронеж', 'россия', 'атмосфера', 'впечатления - туризм', 'норильск', 'калининградская область', 'инстаграм', 'чернобыльская аэс', 'заброшка', 'хэллоуин', 'экскурсия'] \n",
      "\n",
      "текст: МОСКВА, 29 окт — РИА Новости, Мария Селиванова. Перед долгими ноябрьскими праздниками стремительно дорожают авиаперелеты на главные курорты Египта и Турции. Однако бывалые туристы знают, как сэкономит...\n",
      "мои ключевые слова: ['экономия', 'эффект вторника', 'билет', 'турист', 'рейс', 'стыковочный рейс', 'лоукостер', 'авиабилет', 'коронавирус', 'маршрут', 'хорошая цена']\n",
      "ключевые слова с сайта: ['пассажиры', 'авиабилеты', 'туризм', 'россия', 'куда поехать', ' коронавирус covid-19', 'куда можно лететь', 'экономика', 'прага', 'пермь', 'новости - туризм', 'туту.ру', 'стиль жизни', 'отдых на море', 'туристы', 'лайфхак']\n",
      "все ключевые слова (золотой стандарт): ['туризм', 'куда можно лететь', 'маршрут', 'туристы', ' коронавирус covid-19', 'отдых на море', 'турист', 'билет', 'туту.ру', 'авиабилеты', 'прага', 'лоукостер', 'экономия', 'куда поехать', 'рейс', 'новости - туризм', 'стыковочный рейс', 'экономика', 'стиль жизни', 'россия', 'пермь', 'эффект вторника', 'лайфхак', 'пассажиры', 'авиабилет', 'хорошая цена', 'коронавирус'] \n",
      "\n",
      "текст: МОСКВА, 23 окт — РИА Новости, Мария Селиванова. Тропический остров Маргарита непросто найти на карте. Наши туристы перестали посещать его лет пять назад, когда в Венесуэле начался экономический кризис...\n",
      "мои ключевые слова: ['тропический остров маргарита', 'остров', 'тропический остров', 'маргарита', 'венесуэла', 'курорт', 'деньги', 'интернет', 'отдых', 'песчаный пляж', 'пляж', 'достопримечательность', 'музей', 'местная кухня', 'кухня', 'беспошлинная торговля']\n",
      "ключевые слова с сайта: ['достопримечательности', 'еда', 'венесуэла', 'южная америка', 'христофор колумб', 'туризм', 'куда сходить ', 'что посмотреть ', 'куда поехать', 'что приготовить', 'куда можно лететь', 'остров', 'маршруты - туризм', ' коронавирус covid-19', 'отдых на море', 'танзания', 'занзибар', 'горячие туры']\n",
      "все ключевые слова (золотой стандарт): ['песчаный пляж', 'туризм', 'куда можно лететь', 'остров', 'тропический остров маргарита', 'беспошлинная торговля', ' коронавирус covid-19', 'кухня', 'христофор колумб', 'венесуэла', 'отдых на море', 'пляж', 'музей', 'еда', 'отдых', 'деньги', 'куда сходить ', 'куда поехать', 'достопримечательности', 'маршруты - туризм', 'интернет', 'тропический остров', 'местная кухня', 'горячие туры', 'курорт', 'южная америка', 'маргарита', 'занзибар', 'танзания', 'достопримечательность', 'что приготовить', 'что посмотреть '] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_articles)):\n",
    "    concat_keywords(all_articles[i], my_keywords[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "def preprocess(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(m.parse(t)[0].normal_form)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for art in all_articles:\n",
    "    art['text'] = preprocess(art['text'])\n",
    "    key_lemmas = []\n",
    "    for k in art['keywords']:\n",
    "        key_lemmas.append(preprocess(k))\n",
    "    art['keywords'] = list(set(key_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Автоматическое извлечение ключевых слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for art in all_articles:\n",
    "    RAKE_keywords = rake.run(art['text'], maxWords=3, minFrequency=2)\n",
    "    art['RAKE_keywords'] = [r[0] for r in RAKE_keywords if r[1] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for art in all_articles:\n",
    "    TextRank_keywords = keywords.keywords(art['text'], \n",
    "                                          language='russian', \n",
    "                                          additional_stopwords=stops, \n",
    "                                          scores=True)\n",
    "    art['TextRank_keywords'] = [r[0] for r in TextRank_keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [a['text'] for a in all_articles]\n",
    "vectorizer = TfidfVectorizer(stop_words=stops, ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_articles)):\n",
    "    all_articles[i]['TfIdf_keywords'] = df.loc[i][df.loc[i] > 0.07].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Морфологический шаблон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обсуждали, что ключевые слова — это часто имена существительные. В моём золотом стандарте мало биграмм и слов других частей речи, поэтому мой морфологический шаблон — **NOUN** (только униграммы). Зато это будет хотя бы насколько-то что-то показывать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 29.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for art in tqdm(all_articles):\n",
    "    new_dict = {}\n",
    "    for key in art:\n",
    "        if key.endswith('keywords'):\n",
    "            templated = []\n",
    "            for keyword in art[key]:\n",
    "                if m.parse(keyword)[0].tag.POS == 'NOUN':\n",
    "                    templated.append(keyword)\n",
    "            new_dict[key + '_NOUN'] = templated\n",
    "    art.update(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Подсчёт метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(art, method, golden):\n",
    "    predicted = art[method]\n",
    "    TP = len(list(set(golden) & set(predicted)))\n",
    "    precision = TP / len(predicted)\n",
    "    metrics_dict['precision'] += precision\n",
    "    recall = TP / len(golden)\n",
    "    metrics_dict['recall'] += recall\n",
    "    metrics_dict['F1'] += 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "метод: RAKE_keywords\n",
      "точность: 0.16\n",
      "полнота: 0.11\n",
      "F1: 0.12\n",
      "\n",
      "\n",
      "метод: TextRank_keywords\n",
      "точность: 0.07\n",
      "полнота: 0.23\n",
      "F1: 0.11\n",
      "\n",
      "\n",
      "метод: TfIdf_keywords\n",
      "точность: 0.25\n",
      "полнота: 0.14\n",
      "F1: 0.17\n",
      "\n",
      "\n",
      "метод: RAKE_keywords_NOUN\n",
      "точность: 0.23\n",
      "полнота: 0.12\n",
      "F1: 0.15\n",
      "\n",
      "\n",
      "метод: TextRank_keywords_NOUN\n",
      "точность: 0.14\n",
      "полнота: 0.27\n",
      "F1: 0.19\n",
      "\n",
      "\n",
      "метод: TfIdf_keywords_NOUN\n",
      "точность: 0.3\n",
      "полнота: 0.16\n",
      "F1: 0.21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in list(all_articles[0]):\n",
    "    if method in ['text', 'keywords', 'keywords_NOUN']:\n",
    "        continue\n",
    "    metrics_dict = {'precision': 0, 'recall': 0, 'F1': 0}\n",
    "    for art in all_articles:\n",
    "        if method.endswith('_keywords'):\n",
    "            golden = art['keywords']\n",
    "            metrics(art, method, golden)\n",
    "        elif method.endswith('_keywords_NOUN'):\n",
    "            golden = art['keywords_NOUN']\n",
    "            metrics(art, method, golden)\n",
    "    print('метод:', method)\n",
    "    print('точность:', round(metrics_dict['precision'] / len(all_articles), 2))\n",
    "    print('полнота:', round(metrics_dict['recall'] / len(all_articles), 2))\n",
    "    print('F1:', round(metrics_dict['F1'] / len(all_articles), 2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ошибки и решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "золотой стандарт: ['египет', 'туризм', 'куда можно лететь', 'авиакомпания', 'пять звезда', 'чартер', 'турист', 'шарм-эш-шейх', 'коронавирусный инфекция', 'отдых', 'безопасность', 'куда поехать', 'рейс', 'гостиница', 'маршрут - туризм', 'отдых на мор', 'отель', 'хургад', 'самолёт', 'аэропорт']\n",
      "предсказал RAKE: ['шарм-эш-шейх', 'весь включить', 'курорт египет', 'санкт-петербург', 'anex tour', 'tui россия', 'россия', 'число', 'хургад', 'москва', 'человек', 'звезда', 'рейс', 'безопасность', 'интурист', 'неделя', 'екатеринбург', 'казань', 'компания', 'солнце']\n"
     ]
    }
   ],
   "source": [
    "print('золотой стандарт:', all_articles[0]['keywords'])\n",
    "print('предсказал RAKE:', all_articles[0]['RAKE_keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* К сожалению, кажется, что использованные методы выделения ключевых слов зачастую чувствительны к именам собственным, которые не всегда бывают важны для конкретного текста. Возможно, для больших текстов имеет смысл сначала осуществить суммаризацию, а затем выделить ключевые слова, чтобы не останавливаться на чём-то на самом деле не слишком важном.\n",
    "* Кроме того, есть необходимость в расширении использованного списка стоп-слов, даже нейтральные слова типа *хороший* и *человек* могут ухудшать качество.\n",
    "* Контекстуализованные модели (например, BERT) также могут стать неплохим помощником в выделении ключевых слов. Кажется, что контекст действительно важен. Насколько я знаю, таковые уже существуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
